{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Python7Clustering.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyNeWMsSAAqlBf4IAMYnP3tA",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mjfadaei/PythonML/blob/main/Python7Clustering.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "Hm8mPP8vHJAM"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "\n",
        "X = np.array([[5,3],\n",
        "    [10.0,15],\n",
        "    [15,12],\n",
        "    [24,10],\n",
        "    [30,30],\n",
        "    [85,70],\n",
        "    [71,80],\n",
        "    [60,78],\n",
        "    [70,55],\n",
        "    [80,91],])\n",
        "Y = np.array([[0],\n",
        "    [0],\n",
        "    [0],\n",
        "    [1],\n",
        "    [1],\n",
        "    [1],\n",
        "    [1],\n",
        "    [1],\n",
        "    [1],\n",
        "    [1]])"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "labels = range(0, 10)\n",
        "plt.figure(figsize=(10, 7))\n",
        "plt.subplots_adjust(bottom=0.1)\n",
        "plt.scatter(X[:,0],X[:,1], label='True Position')\n",
        "\n",
        "for label, x, y in zip(labels, X[:, 0], X[:, 1]):\n",
        "    plt.annotate(\n",
        "        label,\n",
        "        xy=(x, y), xytext=(-3, 3),\n",
        "        textcoords='offset points', ha='right', va='bottom')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "hZsJggE0HY5f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.cluster import KMeans\n",
        "from sklearn import metrics\n",
        "import pandas as pd\n",
        "import scipy\n",
        "km = KMeans(n_clusters=2, max_iter=50)\n",
        "km.fit(X)\n",
        "predicted = km.predict(X)\n",
        "print(predicted)\n",
        "print('SSE=', km.inertia_)  #  #returns the SSE value\n",
        "labels = range(0, 10)\n",
        "plt.scatter(X[predicted==0,0],X[predicted==0,1],  c='b', label='True Position')\n",
        "plt.scatter(X[predicted==1,0],X[predicted==1,1],  c='r', label='True Position')\n",
        "for label, x, y in zip(labels, X[:, 0], X[:, 1]):\n",
        "    plt.annotate(\n",
        "        label,\n",
        "        xy=(x, y), xytext=(-3, 3),\n",
        "        textcoords='offset points', ha='right', va='bottom')\n",
        "plt.show()\n",
        "\n",
        "\n",
        "# ------------------------------------------------------------Evaluation\n",
        "## -----------------------------------Contingency_matrix\n",
        "contingency_matrix = metrics.cluster.contingency_matrix(Y, predicted)\n",
        "contingency_matrix\n",
        "col=[\"Predicted 0 \",\"Predicted 1\"]\n",
        "ind=['0','1']\n",
        "print(pd.DataFrame(contingency_matrix, index=ind, columns=col))\n",
        "## -----------------------------------------Purity\n",
        "def purity_score(y_true, y_pred):\n",
        "    # compute contingency matrix (also called confusion matrix)\n",
        "    contingency_matrix = metrics.cluster.contingency_matrix(y_true, y_pred)\n",
        "    # return purity\n",
        "    return np.sum(np.amax(contingency_matrix, axis=0)) / np.sum(contingency_matrix)\n",
        "    \n",
        "purity=purity_score(Y, predicted)\n",
        "print(\"purity=\",purity)\n",
        "## --------------------------------------Entropy\n",
        "def Entropy_score(y_true, y_pred):\n",
        "    # compute contingency matrix (also called confusion matrix)\n",
        "    Pi=[]\n",
        "    ei=[]\n",
        "    contingency_matrix = metrics.cluster.contingency_matrix(y_true, y_pred)\n",
        "    Entropy=0\n",
        "    for i in range(len(contingency_matrix[0])):\n",
        "        Pi.append(np.sum(contingency_matrix[:,i]))\n",
        "        ei.append(0)\n",
        "        for j in range(len(contingency_matrix)):\n",
        "            if(contingency_matrix[j,i]!=0):\n",
        "                ei[i]=-1*np.log(contingency_matrix[j,i]/Pi[i])*contingency_matrix[j,i]/Pi[i]\n",
        "        Entropy+=ei[i]*Pi[i]\n",
        "    Entropy=Entropy/sum(Pi)\n",
        "    return  Entropy\n",
        "\n",
        "Entropy=Entropy_score(Y, predicted)\n",
        "print(\"Entropy=\",Entropy)\n",
        "\n",
        "## --------------------------------------\n",
        "proximitymatrix = metrics.pairwise_distances(X)\n",
        "incidencematrix = np.zeros([len(predicted), len(predicted)])\n",
        "corrmat = np.array([])\n",
        "for i in range(len(predicted)):\n",
        "  for j in range(len(predicted)):\n",
        "    if predicted[i] == predicted[j]:\n",
        "      incidencematrix[i,j] = 1\n",
        "    else:\n",
        "      incidencematrix[i,j] = 0\n",
        "for i in range(len(predicted)-1):\n",
        "  for j in range(i+1, len(predicted)):\n",
        "    if corrmat.size == 0:\n",
        "      corrmat = np.array([[proximitymatrix[i,j], incidencematrix[i,j]]])\n",
        "    else:\n",
        "      corrmat = np.append(corrmat, [[proximitymatrix[i,j], incidencematrix[i,j]]], axis =0)\n",
        "corr = np.corrcoef(np.transpose(corrmat))\n",
        "print('Pearsons correlation: %.3f', corr)"
      ],
      "metadata": {
        "id": "uTAcPU_lHveD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.cluster import AgglomerativeClustering\n",
        "import numpy as np\n",
        "from scipy.cluster.hierarchy import dendrogram\n",
        "# ---\n",
        "def plot_dendrogram(model, **kwargs):\n",
        "    # Create linkage matrix and then plot the dendrogram\n",
        "\n",
        "    # create the counts of samples under each node\n",
        "    counts = np.zeros(model.children_.shape[0])\n",
        "    n_samples = len(model.labels_)\n",
        "    for i, merge in enumerate(model.children_):\n",
        "        current_count = 0\n",
        "        for child_idx in merge:\n",
        "            if child_idx < n_samples:\n",
        "                current_count += 1  # leaf node\n",
        "            else:\n",
        "                current_count += counts[child_idx - n_samples]\n",
        "        counts[i] = current_count\n",
        "\n",
        "    linkage_matrix = np.column_stack(\n",
        "        [model.children_, model.distances_, counts]\n",
        "    ).astype(float)\n",
        "\n",
        "    # Plot the corresponding dendrogram\n",
        "    dendrogram(linkage_matrix, **kwargs)\n",
        "# ---\n",
        "modelsingle = AgglomerativeClustering(distance_threshold=0, n_clusters=None, linkage=\"single\")\n",
        "modelsingle.fit(X)\n",
        "print('linkage:single=',modelsingle.labels_)\n",
        "plot_dendrogram(modelsingle)\n",
        "plt.xlabel(\"Number of points in node (or index of point if no parenthesis).\")\n",
        "plt.show()\n",
        "\n",
        "modelcomplete = AgglomerativeClustering(distance_threshold=0, n_clusters=None, linkage=\"complete\")\n",
        "modelcomplete.fit(X)\n",
        "print('linkage:complete=',modelcomplete.labels_)\n",
        "plot_dendrogram(modelcomplete)\n",
        "plt.xlabel(\"Number of points in node (or index of point if no parenthesis).\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "MXsvgF3mmdgg"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}